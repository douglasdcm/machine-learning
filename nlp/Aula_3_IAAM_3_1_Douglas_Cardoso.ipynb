{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-Mgum7LZZmf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: afinn in /home/douglas/.local/lib/python3.8/site-packages (0.1)\n",
      "/bin/bash: python: command not found\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: vaderSentiment in /home/douglas/.local/lib/python3.8/site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from vaderSentiment) (2.22.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyemd in /home/douglas/.local/lib/python3.8/site-packages (0.5.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.9.0 in /home/douglas/.local/lib/python3.8/site-packages (from pyemd) (1.19.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install afinn\n",
    "!python -m textblob.download_corpora\n",
    "!pip install -U textblob\n",
    "!pip install vaderSentiment\n",
    "!pip install pyemd\n",
    "!pip install unidecode\n",
    "!pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SR9dcTSYZZml"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from unidecode import unidecode\n",
    "import pandas as pd\n",
    "import bz2\n",
    "import gensim\n",
    "import warnings\n",
    "import numpy as np\n",
    "from gensim.models import word2vec\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AjOYV0cfZZmq"
   },
   "source": [
    "# Carregando os embeddings\n",
    "\n",
    "Aqui vamos utilizar os embeddings para realizar as seguintes atividades:\n",
    "\n",
    "- análise de simlaridade\n",
    "- classificação de documentos\n",
    "\n",
    "<b> Carregue os embeddings treinados, como vimos na Aula 2. É o mesmo arquivo que iremos utilizar</b>\n",
    "\n",
    "Link: https://drive.google.com/open?id=1zI8pGfbUHuU_0wY_FV4tD6w6ZCUJTQbh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "XqMDMgrBZZmr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 1s, sys: 1.27 s, total: 1min 2s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "newfilepath = \"embedding_wiki_100d_pt.txt\"\n",
    "filepath = \"ptwiki_20180420_100d.txt.bz2\"\n",
    "with open(newfilepath, 'wb') as new_file, bz2.BZ2File(filepath, 'rb') as file:\n",
    "    for data in iter(lambda : file.read(100 * 1024), b''):\n",
    "        new_file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregar\n",
    "%%time\n",
    "word_vectors = gensim.models.KeyedVectors.load_word2vec_format(filepath, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqZJuktuZZmv"
   },
   "source": [
    "# Similaridade de Documentos\n",
    "\n",
    "Para realizar a similaridade entre documentos, utilize as frases abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "T-YjfkcTZZmw"
   },
   "outputs": [],
   "source": [
    "frase1 = \"Excelente produto chegou antes do prazo indico e recomendo produto bom pois já testei e foi mais que aprovado\" \n",
    "frase2 = \"SUPER RECOMENDO, PREÇO, QUALIDADE #BRASTEMP, EFICIÊNCIA NA ENTREGA, E FACILIDADE DE PAGAMENTO. MUITO BOM!!!\"\n",
    "frase3 = \"A tampa do fogão veio com problemas com o pino de encaixe solto e precisa de reparos\"\n",
    "frase4 = \"Fogão ótimo!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNGfjS5RZZm1"
   },
   "source": [
    "## Distância de Jaccard\n",
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "1) Faça um método que calcule a similaridade de Jaccard e aplique para os seguintes pares de frases:\n",
    "\n",
    "- Frase1 e Frase2\n",
    "- Frase1 e Frase3\n",
    "- Frase2 e Frase3\n",
    "- Frase1 e Frase4\n",
    "\n",
    "Observação: lembrando que você precisa aplicar um pre-processamento nessas frases antes de aplicar o método.\n",
    "Faça:\n",
    "\n",
    "- Lower\n",
    "- Remoção StopWords\n",
    "- Remoção Pontuação\n",
    "- Tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/douglas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "yn2YYL7bZZm2"
   },
   "outputs": [],
   "source": [
    "def pre_processamento_texto(corpus):\n",
    "\n",
    "    #tokenizacao\n",
    "    corpus_alt = re.findall(r\"\\w+(?:'\\w+)?|[^\\w\\s]\", corpus)\n",
    "    #capitalizacao\n",
    "    corpus_alt = [t.lower() for t in corpus_alt]\n",
    "    #remover stopwords\n",
    "    stopwords_ = stopwords.words(\"portuguese\")\n",
    "    corpus_alt = [t for t in corpus_alt if t not in stopwords_]\n",
    "    #remover pontuacoes\n",
    "    corpus_alt = [t for t in corpus_alt if t not in string.punctuation]\n",
    "\n",
    "    return corpus_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase1_pre_processada = pre_processamento_texto(frase1)\n",
    "frase2_pre_processada = pre_processamento_texto(frase2)\n",
    "frase3_pre_processada = pre_processamento_texto(frase3)\n",
    "frase4_pre_processada = pre_processamento_texto(frase4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['excelente',\n",
       " 'produto',\n",
       " 'chegou',\n",
       " 'antes',\n",
       " 'prazo',\n",
       " 'indico',\n",
       " 'recomendo',\n",
       " 'produto',\n",
       " 'bom',\n",
       " 'pois',\n",
       " 'testei',\n",
       " 'aprovado']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frase1_pre_processada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(f1, f2):\n",
    "    f1 = set(f1)\n",
    "    f2 = set(f2)\n",
    "    \n",
    "    intersecao = f1.intersection(f2)\n",
    "    uniao = f1.union(f2)\n",
    "    \n",
    "    return len(intersecao) / len(uniao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10526315789473684\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(jaccard_similarity(frase1_pre_processada, frase2_pre_processada))\n",
    "print(jaccard_similarity(frase1_pre_processada, frase3_pre_processada))\n",
    "print(jaccard_similarity(frase2_pre_processada, frase3_pre_processada))\n",
    "print(jaccard_similarity(frase1_pre_processada, frase4_pre_processada))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ke1PVggcZZm8"
   },
   "source": [
    "<b> Atividade </b>\n",
    "\n",
    "2) Qual par de frase teve maior simlaridade? E qual teve menor? Este resultado faz sentido? Explique.\n",
    "\n",
    "O par frase1 e frase2, pois as duas frases possuem algumas palavras em comum, logo a inerseção entre elas é diferente de zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3g7wRRl_ZZm9"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ND3usAELZZm-"
   },
   "source": [
    "## Distância de Cosseno\n",
    "\n",
    "Aqui iremos calcular a distância do cosseno utilizando duas formas, que aprendemos na aula passada, para representar o texto.\n",
    "\n",
    "- Bag of Words (BOW) \n",
    "- Embedding\n",
    "\n",
    "Observação:\n",
    "\n",
    "Existem duas formas de trabalhar com o cosseno:\n",
    "\n",
    "<b> Distância </b>: quanto menor mais perto estão as frases.\n",
    "<b> Similaridade </b>: quanto maior mais perto estão as frases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_Qw93ZLZZm-"
   },
   "source": [
    "### BOW - Distância do cosseno\n",
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "3) Calcule a distância do cosseno utilizando a representação CountVectorizer e aplique para os seguintes pares de frases:\n",
    "\n",
    "- Frase1 e Frase2\n",
    "- Frase1 e Frase3\n",
    "- Frase2 e Frase3\n",
    "- Frase1 e Frase4\n",
    "\n",
    "Observação: no CountVectorizer utilizem as frases já pre-processadas da atividade anterior. Mas para aplicá-las no fit_transform, cada frase deve ser um string (sem estar tokenizada) dentro de uma lista.\n",
    "\n",
    "```python\n",
    "#exemplo\n",
    "distance.cosine(frase1, frase2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7CzqpPPGZZm_"
   },
   "outputs": [],
   "source": [
    "bow = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "frases = [' '.join(frase1_pre_processada), ' '.join(frase2_pre_processada),\n",
    "          ' '.join(frase3_pre_processada), ' '.join(frase4_pre_processada)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_bow = bow.fit_transform(frases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x29 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 32 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 2, 0,\n",
       "         1, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "         1, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "         0, 1, 1, 0, 1, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_bow.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase1_bow = vector_bow.todense()[0]\n",
    "frase2_bow = vector_bow.todense()[1]\n",
    "frase3_bow = vector_bow.todense()[2]\n",
    "frase4_bow = vector_bow.todense()[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 2, 0,\n",
       "         1, 0, 0, 0, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frase1_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8309691490542968\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(distance.cosine(frase1_bow, frase2_bow))\n",
    "print(distance.cosine(frase1_bow, frase3_bow))\n",
    "print(distance.cosine(frase2_bow, frase3_bow))\n",
    "print(distance.cosine(frase1_bow, frase4_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rcFS1MKzZZnE"
   },
   "source": [
    "<b> Atividade </b>\n",
    "\n",
    "\n",
    "4) Qual par de frase teve maior distância? E qual teve menor? Este resultado faz sentido? Explique.\n",
    "\n",
    "Os pares de frases frase1 e frase3, frase2 e frase3, e frase 1 e frase4 tiveram as maiores distâncias. Isso porque estas frases não têm nenhuma palavra em comum.\n",
    "\n",
    "O par com menor distâcia foi o frase1 e frase2, pois possuem lagumas palavras em comum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buNHHZPgZZnF"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3G4ckzlZZnN"
   },
   "source": [
    "### Embedding - Distância do cosseno\n",
    "\n",
    "Para calcular o embedding de cada uma das frases, utilize o modelo carregado inicialmente. \n",
    "\n",
    "Cada palavra tem um vetor, para formar o embedding da frase tire a média de todos os vetores.\n",
    "\n",
    "Utilize as frases já pre-processadas\n",
    "\n",
    "<b> Atividade </b> \n",
    "\n",
    "5) Calcule a distância do cosseno utilizando a representação Embedding e aplique para os seguintes pares de frases:\n",
    "\n",
    "- Frase1 e Frase2\n",
    "- Frase1 e Frase3\n",
    "- Frase2 e Frase3\n",
    "- Frase1 e Frase4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x7fe2f31944c0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "rRO8RnLgZZnO"
   },
   "outputs": [],
   "source": [
    "def calcula_embedding(frase):\n",
    "    return np.mean(np.array([word_vectors[palavra] for palavra in frase if palavra in word_vectors.vocab]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase1_vector_embedding = calcula_embedding(frase1_pre_processada)\n",
    "frase2_vector_embedding = calcula_embedding(frase2_pre_processada)\n",
    "frase3_vector_embedding = calcula_embedding(frase3_pre_processada)\n",
    "frase4_vector_embedding = calcula_embedding(frase4_pre_processada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3227    ,  0.34005833, -0.12894166, -0.10406666, -0.4845917 ,\n",
       "       -0.29425833,  0.12635   ,  0.49035   , -0.2429    ,  0.522125  ,\n",
       "        0.20710002,  0.09579167, -0.485775  ,  0.06400833,  0.05996667,\n",
       "        0.0134    ,  0.36394164, -0.3865333 , -0.19614166,  0.04160834,\n",
       "        0.129625  ,  0.133325  , -0.13795833, -0.16118333, -0.12135834,\n",
       "        0.07021666, -0.34681666, -0.41391668, -0.09325833,  0.26530832,\n",
       "       -0.09575   , -0.03753333,  0.25401667,  0.310675  ,  0.01769167,\n",
       "       -0.173275  ,  0.04813334,  0.27826664,  0.257025  , -0.25668335,\n",
       "        0.30625832,  0.06915832, -0.44500837, -0.09507499,  0.01294167,\n",
       "       -0.047425  , -0.19609167, -0.0149    , -0.67545   ,  0.26777497,\n",
       "        0.36566666,  0.06413333, -0.06512501, -0.02040833,  0.37386668,\n",
       "       -0.24394165, -0.18075836, -0.19190834, -0.04534167,  0.16798331,\n",
       "        0.5301833 , -0.16669166, -0.23428333,  0.25604165, -0.03947499,\n",
       "       -0.05850834, -0.33455002,  0.160325  ,  0.03743334, -0.01781667,\n",
       "       -0.20192498,  0.011475  , -0.23661667, -0.41531667, -0.12218333,\n",
       "       -0.13258334, -0.17128335,  0.17880833, -0.001925  , -0.10397501,\n",
       "       -0.07726666, -0.05871667, -0.25461668, -0.21444167, -0.42201665,\n",
       "        0.08128333, -0.08521666, -0.24510002,  0.094125  , -0.14821668,\n",
       "        0.66397494, -0.37226668, -0.12711667, -0.13659167,  0.07375   ,\n",
       "       -0.25778332,  0.09605   , -0.06324167, -0.21470833, -0.007025  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frase1_vector_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16096973419189453\n",
      "0.2234203815460205\n",
      "0.2526938319206238\n",
      "0.29043054580688477\n"
     ]
    }
   ],
   "source": [
    "print(distance.cosine(frase1_vector_embedding, frase2_vector_embedding))\n",
    "print(distance.cosine(frase1_vector_embedding, frase3_vector_embedding))\n",
    "print(distance.cosine(frase2_vector_embedding, frase3_vector_embedding))\n",
    "print(distance.cosine(frase1_vector_embedding, frase4_vector_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excelente produto chegou antes do prazo indico e recomendo produto bom pois já testei e foi mais que aprovado\n",
      "SUPER RECOMENDO, PREÇO, QUALIDADE #BRASTEMP, EFICIÊNCIA NA ENTREGA, E FACILIDADE DE PAGAMENTO. MUITO BOM!!!\n",
      "A tampa do fogão veio com problemas com o pino de encaixe solto e precisa de reparos\n",
      "Fogão ótimo!\n"
     ]
    }
   ],
   "source": [
    "print(frase1)\n",
    "print(frase2)\n",
    "print(frase3)\n",
    "print(frase4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgZWHiGSZZnT"
   },
   "source": [
    "<b>Atividade </b>\n",
    "\n",
    "6) Qual par de frase teve maior distância? E qual teve menor? Este resultado faz sentido? Explique.\n",
    "\n",
    "O par de frases com maior distância foi o frase1 e frase4. A que teve menor distância foi o par frase1 e frase2.\n",
    "\n",
    "O resultado faz sentido para as frases com menor distânica, pois ambas falam positivamente de algum produto.\n",
    "Já o resulatdo da frase1 com a frase4 deveria ter tido uma distância menor, pois as duas frases também falam positivamente de algum produto.\n",
    "\n",
    "Como estamos recuperando a médias dos embeddings, pode ser que o vetor de alguma(s) palavra(s) das duas frases esteja \"pesando\" mais em relação aos outros e distanciando as médias dos embeddings fazendo a distâcia entre as frases ficar maior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsFFxOoeZZnU"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hx5acLVhZZne"
   },
   "source": [
    "## WMD\n",
    "\n",
    "O WMD já está incorporado ao Word2Vec\n",
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "7) Calcule a distância WMD e aplique para os seguintes pares de frases:\n",
    "\n",
    "- Frase1 e Frase2\n",
    "- Frase1 e Frase3\n",
    "- Frase2 e Frase3\n",
    "- Frase1 e Frase4\n",
    "\n",
    "Observação: use a variável já tokenizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "o0881q7vZZne"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0725697404938526\n",
      "3.759219170455064\n",
      "3.9048993635316385\n",
      "3.851623338336251\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors.wmdistance(frase1_pre_processada, frase2_pre_processada))\n",
    "print(word_vectors.wmdistance(frase1_pre_processada, frase3_pre_processada))\n",
    "print(word_vectors.wmdistance(frase2_pre_processada, frase3_pre_processada))\n",
    "print(word_vectors.wmdistance(frase1_pre_processada, frase4_pre_processada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsIENn25ZZni"
   },
   "source": [
    "<b> Atividade </b>\n",
    "\n",
    "8) Qual par de frase teve maior distância? E qual teve menor? Este resultado faz sentido? Explique.\n",
    "\n",
    "O par de frases com a maior distância foi frase2 e frase3. O par com menor distância foi frase1 e frase2.\n",
    "\n",
    "O resultado faz sentido, pois as frases frase2 e frase3 expressam opniões diverntes em relação a um determinado produto: a frase2 fala positivamente sobre um produto, enquanto a frase3 fala negativamente.\n",
    "\n",
    "Para o par frase1 e frase2 também faz sentido, pois ambas as frases falam positivamente de um determinado produto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhC4OvGWZZnj"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXHGivtDZZnk"
   },
   "source": [
    "# Classificação de Documentos\n",
    "\n",
    "A clssificação de documentos é muito útil em vários aspectos. Um dos tipos de classificação de texto é a análise de sentimentos.\n",
    "\n",
    "A fim de ilustrar a classificação de documentos iremos criar um modelo para classificar uma frase como positiva ou negativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhCOoEn7ZZno"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "9) Carregue o dataset com o pandas e depois dê o head no dataframe.\n",
    "\n",
    "\n",
    "Link download: https://drive.google.com/open?id=15azJWdEEPGsXQGiDmEOseTBJcquWvBQc\n",
    "\n",
    "<b> Este dataset é sobre revisões de filmes do IMDB. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "eI0oXiOoZZnp"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"imdb-reviews-pt-br.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "YJYAOZecZZnv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_en</th>\n",
       "      <th>text_pt</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Brass pictures movies is not a fitting word fo...</td>\n",
       "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            text_en  \\\n",
       "0   1  Once again Mr. Costner has dragged out a movie...   \n",
       "1   2  This is an example of why the majority of acti...   \n",
       "2   3  First of all I hate those moronic rappers, who...   \n",
       "3   4  Not even the Beatles could write songs everyon...   \n",
       "4   5  Brass pictures movies is not a fitting word fo...   \n",
       "\n",
       "                                             text_pt sentiment  \n",
       "0  Mais uma vez, o Sr. Costner arrumou um filme p...       neg  \n",
       "1  Este é um exemplo do motivo pelo qual a maiori...       neg  \n",
       "2  Primeiro de tudo eu odeio esses raps imbecis, ...       neg  \n",
       "3  Nem mesmo os Beatles puderam escrever músicas ...       neg  \n",
       "4  Filmes de fotos de latão não é uma palavra apr...       neg  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCKr5KPMZZnz"
   },
   "source": [
    "## Representação dos dados\n",
    "\n",
    "O sentimento positivo e negativo iremos binarizar cada um deles. Seja 1 positivo e 0 negativo.\n",
    "\n",
    "Iremos representar o texto de duas formas:\n",
    "\n",
    "- Bag of Words (BOW)\n",
    "- Embedding\n",
    "\n",
    "Depois iremos comparar o resultado de cada um deles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "POkSAiYMZZn0"
   },
   "source": [
    "### Representação Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0mYbWgcZZn1"
   },
   "source": [
    "<b> Atividade </b>\n",
    "\n",
    "10) Faça a representação dos sentimentos. 1 positivo; 0 negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "aBkDjo4VZZn2"
   },
   "outputs": [],
   "source": [
    "target = df[\"sentiment\"].replace([\"neg\", \"pos\"], [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "49454    1\n",
       "49455    1\n",
       "49456    1\n",
       "49457    1\n",
       "49458    1\n",
       "Name: sentiment, Length: 49459, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8VgGgUnZZn8"
   },
   "source": [
    "### Bag of Words (BOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xirBWWCzZZn-"
   },
   "source": [
    "<b> Atividade </b>\n",
    "\n",
    "11) Aplique o pré-processamento listado abaixo na coluna ``text_pt`` (crie uma nova coluna ```text_pt_sem_stopwords``` no dataframe para armazenar este dado processado):\n",
    "\n",
    "- Remova as stopwords do texto\n",
    "- Remova as pontuções\n",
    "- Mantenha o texto sem tokenização, ou seja uma string\n",
    "\n",
    "<b> Dica: </b> use o ```progress_apply``` para exibir a barra de progresso:\n",
    "\n",
    "```python\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "df[\"colunas\"].progress_apply(lambda x: preprocessamento(x))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DnJokm8VZZn-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processamento_string(corpus):\n",
    "\n",
    "    #tokenizacao\n",
    "    corpus_alt = re.findall(r\"\\w+(?:'\\w+)?|[^\\w\\s]\", corpus)\n",
    "    #capitalizacao\n",
    "    corpus_alt = [t.lower() for t in corpus_alt]\n",
    "    #remover stopwords\n",
    "    stopwords_ = stopwords.words(\"portuguese\")\n",
    "    corpus_alt = [t for t in corpus_alt if t not in stopwords_]\n",
    "    #remover pontuacoes\n",
    "    corpus_alt = [t for t in corpus_alt if t not in string.punctuation]\n",
    "    \n",
    "    corpus_alt = ' '.join(corpus_alt)\n",
    "    return corpus_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe6b326717d4c85a29dc48dcd7702a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=49459.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df[\"text_pt_sem_stopwords\"] = df[\"text_pt\"].progress_apply(lambda x : pre_processamento_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TddT2Y6JZZoC"
   },
   "source": [
    "<b> Atividade </b>\n",
    "\n",
    "12) Aplique a representação do texto processado anteriormente com CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "axSZo69tZZoC"
   },
   "outputs": [],
   "source": [
    "bow = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "frases = df[\"text_pt_sem_stopwords\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['vez sr costner arrumou filme tempo necessário além terríveis seqüências resgate mar quais poucas simplesmente importei nenhum personagens maioria fantasmas armário personagem costers realizado logo início esquecido tarde importava personagem deveríamos importar arrogante superconfiante ashton kutcher problema sai garoto pensa melhor qualquer outra pessoa redor mostra sinais armário desordenado único obstáculo parece estar vencendo costner finalmente bem além meio caminho costner conta sobre fantasmas kutchers informados kutcher levado ser melhor pressentimentos presságios anteriores nenhuma mágica aqui tudo podia fazer desligar hora',\n",
       "       'exemplo motivo maioria filmes ação mesmos genérico chato nada valha pena assistir aqui completo desperdício talentos ice t cubo gelo mal aproveitados cada comprovando capazes atuar agir bem incomode vá ver new jack city ricochet assistir new york undercover ice t boyz hood higher learning friday ice cube ver negócio real ice ts horrivelmente clichê diálogo sozinho faz filme ralar dentes ainda perguntando diabos bill paxton fazendo neste filme diabos sempre interpreta exatamente personagem extraterrestres diante todos filmes vi bill paxton fizeram interpretar exatamente personagem irritante menos aliens personagem morreu tornou pouco gratificante geral lixo ação segunda classe existem incontáveis \\u200b \\u200b filmes melhores ver realmente quiser ver filme assista judgment night praticamente cópia carbono melhor atuação roteiro melhor única coisa fez valer pena assistir mão decente câmera cinematografia quase refrescante chega perto compensar horrível filme si bem assim 4 10',\n",
       "       'primeiro tudo odeio raps imbecis poderiam agir arma pressionada contra testas tudo fazem amaldiçoar atirar outro agir versão clichê gangsters filme leva cinco minutos explicar acontecendo antes armazém único personagem simpático nesse filme exceção teto único metade cérebro william paxton william sadler ambos hill billies sadler tão vilão quanto gângsteres gostava desde começo filme cheio violência sentido especialidade walter hills pessoas caindo janelas vidros voando toda parte praticamente nenhum enredo grande problema torce ninguém todo mundo morre exceto paxton teto todos recebem merecem dois únicos negros podem atuar teto viciado atores profissão irritantes rappers feios fique longe dessa porcaria observe 48 horas 1 2 vez disso mínimo têm personagens gosta senso humor nada além atores reais elenco',\n",
       "       ...,\n",
       "       'espantado forma filme maioria outros média 5 estrelas menor filmes baixa qualidade média 7 10 estrelas imdb mentalidade fanboy ataca novamente filme saiu quase todo mundo bateu ex namorada disse filme questionável anos sentei assistir filme vi aproveitando rindo pouco assassinos substituição filmes pessoas rotulando diretor antoine fuqua negro michael bay vejo maioria filmes fuquas inteligentes qualquer coisa michael bay inventado qualquer forma história alvin sandersjamie foxx ex presidiário usado nonsense agente tesouro edgardavid morse peão pegar assassino chamado bristoldoug hutchinson alvins todos movimentos rastreados bug implantado mandíbula após acidente enquanto agentes atrás bristol bristol atrás tijolos ouro levados assalto deu errado jamie foxx tão divertido quanto alvin sanders alvin falador rápido esperto deixa transparecer doug hutchinson bem bristol pode ser over the top vezes comportamento john malkovitchesque melhor aqui looney bin jim punisher war zone david morse bom agente tesouro mike epps engraçado irmão alvin stevie tanto quanto jamie alguns momentos engraçados tela única falha filme algumas tentativas suspense caem surpresa cenário pista corrida cavalos exagerado consegui desviar olhar diretor todo lá então ganha pontos além disso cena bomba agente tesouro amarrado cadeira enquanto detonador descansa porta bem bacana tudo todas iscas filme ruim longo tiro nunca chato sempre engraçado verificando relógio cada minuto deve contar alguma coisa bait filmes subestimados período 2000 ps crítico alegou filme violento quanto tempo vive sob rocha certeza viu série die hard cada filme quentin tarantino filmes violentos certo esquisito',\n",
       "       'christmas together realmente veio antes tempo criado john denver músicas deste especial sempre músicas natal família durante anos fita cassete feita disco significava natal alguns anos atrás finalmente consegui encontrar vídeo ebay então ouvir toda música 21 anos pude ver john muppets ação mim chance divertido boa música comovente brega interessante ver versões muppets anos 70 compará las versões recentes hoje acredito denver realmente pouco calor fazer show acho normalmente artistas comprometem imagens fazendo sing longs muppets feliz feito consiga rastrear vídeo trilha sonora vale pena alguns favoritos tradicionais muppified algumas músicas originais denver',\n",
       "       'drama romântico classe trabalhadora diretor martin ritt tão inacreditável quanto momentos prazer devido principalmente carisma estrelas jane fonda robert niro ambos ótimos viúva pode seguir frente analfabeta inventora armários provavelmente pode adivinhar resto adaptação romance pat barkers union street título melhor tão descontraído beirar graça edição filmes bagunça ainda agradável fantasia colarinho azul tons rosados aberturas questões sérias ângulo analfabetismo apenas ferramenta enredo história amor segue fogos artifício reais embora personagens intencionalmente pouco incolores derivações reduzidas nível interessante final puro fluff cínicos acharão difícil engolir embora dois personagens mereçam final feliz foto realmente satisfatória outra maneira partir'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frases.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_bow = bow.fit_transform(frases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<49459x129447 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5072221 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mELsQ0tvZZoF"
   },
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSUe-Yr_ZZoG"
   },
   "source": [
    "<b> Atividade </b>\n",
    "\n",
    "13) Aplique o pré-processamento listado abaixo na coluna ``text_pt`` (crie uma nova coluna ```text_pt_sem_stopwords_token``` no dataframe para armazenar este dado processado):\n",
    "\n",
    "- Aplique lower\n",
    "- Remova as stopwords do texto\n",
    "- Remova as pontuções\n",
    "- Mantenha o texto com tokenização\n",
    "\n",
    "<b> Dica: </b> use o ```progress_apply``` para exibir a barra de progresso:\n",
    "\n",
    "```python\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "df[\"colunas\"].progress_apply(lambda x: preprocessamento(x))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "rBJxB_SsZZoH"
   },
   "outputs": [],
   "source": [
    "def pre_processamento_token(corpus):\n",
    "\n",
    "    #tokenizacao\n",
    "    corpus_alt = re.findall(r\"\\w+(?:'\\w+)?|[^\\w\\s]\", corpus)\n",
    "    #capitalizacao\n",
    "    corpus_alt = [t.lower() for t in corpus_alt]\n",
    "    #remover stopwords\n",
    "    stopwords_ = stopwords.words(\"portuguese\")\n",
    "    corpus_alt = [t for t in corpus_alt if t not in stopwords_]\n",
    "    #remover pontuacoes\n",
    "    corpus_alt = [t for t in corpus_alt if t not in string.punctuation]\n",
    "\n",
    "    return corpus_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01da00366e944ad69e69e35836437f48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=49459.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df[\"text_pt_sem_stopwords_token\"] = df[\"text_pt\"].progress_apply(lambda x : pre_processamento_token(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZPhMIrWZZoM"
   },
   "source": [
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "14) Aplique a representação do texto com Embeddings. Cada palavra tem um embedding, o embedding da frase é a média de todos embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4adcd84560434d62abf1569296fe8169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=49459.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vetor_embedding = df[\"text_pt_sem_stopwords_token\"].progress_apply(lambda x : calcula_embedding(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4gg0S5NZZoM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqPJf0yLZZoQ"
   },
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_xhW7e2ZZoQ"
   },
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kpcc167FZZoR"
   },
   "source": [
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "15) Faça a divisão dados dados em treino e teste como no exemplo abaixo:\n",
    "\n",
    "```python\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(X_bag, target,random_state=123)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "E3MeGchRZZoS"
   },
   "outputs": [],
   "source": [
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(vector_bow, target,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37094, 129447)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37094,)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12365, 129447)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12365,)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0ggm8ZLZZoY"
   },
   "source": [
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "16) Treine com uma regressão logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "PJN8KMHiZZoa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_bow = LogisticRegression()\n",
    "modelo_bow.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivlITfC2ZZof"
   },
   "source": [
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "17) Calcule as métricas de resultado utilizando método abaixo:\n",
    "\n",
    "```python\n",
    "print(classification_report(y_test_bow, y_pred))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "TsfRxqjSZZog"
   },
   "outputs": [],
   "source": [
    "preds = modelo_bow.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88      6112\n",
      "           1       0.87      0.89      0.88      6253\n",
      "\n",
      "    accuracy                           0.88     12365\n",
      "   macro avg       0.88      0.88      0.88     12365\n",
      "weighted avg       0.88      0.88      0.88     12365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_bow, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eiulNTGNZZoj"
   },
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6abN65iqZZok"
   },
   "source": [
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "18) Faça a divisão dados dados em treino e teste como no exemplo abaixo:\n",
    "\n",
    "Verifique o shape do X treino e X teste. Caso eles estejam com apenas uma dimensão, você precisa tranformá-los para duas dimensões, caso contrário ocorrerá erro no treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "yn57b04_ZZol"
   },
   "outputs": [],
   "source": [
    "X_train_emb, X_test_emb, y_train_emb, y_test_emb = train_test_split(vetor_embedding, target,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_emb = pd.DataFrame([x for x in X_train_emb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37094, 100)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vetor_embedding[1000].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9BR0H7fZZop"
   },
   "source": [
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "19) Treine com uma regressão logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "hJI29fY2ZZoq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_emb = LogisticRegression()\n",
    "modelo_emb.fit(X_train_emb, y_train_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvIYI1lJZZow"
   },
   "source": [
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "20) Calcule as métricas de resultado utilizando método abaixo:\n",
    "\n",
    "```python\n",
    "print(classification_report(y_test_bow, y_pred))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClFB32whZZox"
   },
   "source": [
    "#### Calcule as métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_emb = pd.DataFrame([x for x in X_test_emb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "G-dRYhR_ZZoy"
   },
   "outputs": [],
   "source": [
    "preds = modelo_emb.predict(X_test_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      6112\n",
      "           1       0.78      0.77      0.77      6253\n",
      "\n",
      "    accuracy                           0.77     12365\n",
      "   macro avg       0.77      0.77      0.77     12365\n",
      "weighted avg       0.77      0.77      0.77     12365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_emb, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sp62Sb1ZZo1"
   },
   "source": [
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "21) Compare os resultados obtidos com o BagOfWords e com o Embedding. Explique os possíveis motivos desta diferença."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RShZ0680ZZo2"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-oH0GQfZZo3"
   },
   "source": [
    "# Análise de sentimentos\n",
    "\n",
    "O modelo que criamos anteriormente é para ilustrar como podemos realizar classificação de documentos.\n",
    "Quando a tarefa é sobre análise de sentimentos, temos duas opções: treinar nosso próprio modelo, como feito anteriormente ou utilizar uma das inúmeras ferramentas prontas.\n",
    "\n",
    "Vamos testar as seguintes ferramentas:\n",
    "\n",
    "- Vader\n",
    "- Textblob\n",
    "- Affin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilpNXE0cZZo3"
   },
   "source": [
    "Nesta atividade iremos utilizar as duas variáveis abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "Pq0dLI9JZZo4"
   },
   "outputs": [],
   "source": [
    "texto_neg = df.loc[0, \"text_en\"]\n",
    "texto_pos = df.loc[49431, \"text_en\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dB-FuBgZZo9"
   },
   "source": [
    "## Vader\n",
    "\n",
    "<b> Apenas Inglês </b>\n",
    "\n",
    "O VADER (Valence Aware Dictionary e sEntiment Reasoner) é uma ferramenta de análise de sentimentos baseada em regras e léxico, especificamente identifica os sentimentos expressos nas mídias sociais.\n",
    "\n",
    "- positive sentiment: compound score >= 0.05\n",
    "- neutral sentiment: (compound score > -0.05) e (compound score < 0.05)\n",
    "- negative sentiment: compound score <= -0.05\n",
    "\n",
    "Mais informações: https://github.com/cjhutto/vaderSentiment\n",
    "\n",
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "22) Aplique este método nas revisões ```texto_pos``` e ```texto_neg```.\n",
    "Para aplicar:\n",
    "\n",
    "```python\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "analyzer.polarity_scores(texto)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "vZE5KL-9ZZo9"
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "qzsgloUpZZpB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.126, 'neu': 0.76, 'pos': 0.114, 'compound': 0.3958}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "analyzer.polarity_scores(texto_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.084, 'neu': 0.737, 'pos': 0.179, 'compound': 0.9969}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.polarity_scores(texto_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDrJTCfKZZpE"
   },
   "source": [
    "## TextBlob\n",
    "\n",
    "<b> Apenas inglês </b>\n",
    "\n",
    "https://www.presentslide.in/2019/08/sentiment-analysis-textblob-library.html\n",
    "\n",
    "<b> Atividade </b>\n",
    " \n",
    "23) Aplique este método nas revisões ```texto_pos``` e ```texto_neg```.\n",
    "Para aplicar:\n",
    "\n",
    "```python\n",
    "sentence=TextBlob(texto)\n",
    "sentence.sentiment\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "D9IvBg5sZZpE"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "R-BV6UkOZZpJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.06385964912280702, subjectivity=0.5629824561403508)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=TextBlob(texto_neg)\n",
    "sentence.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.190819118692253, subjectivity=0.6026226012793177)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=TextBlob(texto_pos)\n",
    "sentence.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xwk7dHuFZZpO"
   },
   "source": [
    "## Afinn\n",
    "\n",
    "- Valor maior que 0 indica sentimento positivo\n",
    "- Valor menor que 0 indica sentimento negativo\n",
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "24) Aplique este método nas revisões ```texto_pos``` e ```texto_neg```.\n",
    "Para aplicar:\n",
    "\n",
    "```python\n",
    "afinn = Afinn()\n",
    "afinn.score(texto)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "C2FS5AUsZZpP"
   },
   "outputs": [],
   "source": [
    "from afinn import Afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "iF8E0CjzZZpX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afinn = Afinn()\n",
    "afinn.score(texto_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afinn.score(texto_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkhkDVIxZZpa"
   },
   "source": [
    "<b> Atividade </b>\n",
    "\n",
    "25) Para você, qual ferramenta teve melhor comportamento?\n",
    "\n",
    "Para mim a Vader teve um comportamento melhor, pois apresenta os sentimentos clasificados por positivos, negativos, neutros e mistos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWImUeS0ZZpb"
   },
   "source": [
    "# Dica:\n",
    "## Quando for trabalhar com um dataset em inglês, a biblioteca Spacy facilita!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gONqxhviZZpc"
   },
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3hj3KE97ZZph"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zW0GLnhVZZpn"
   },
   "source": [
    "O scpay forne um pacote que já tem série de modelos já treinados em NLP. Inclusive para os embeddings em inglês.\n",
    "\n",
    "Para mais informações vá em:\n",
    "\n",
    "https://spacy.io/models/en#en_core_web_md\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v02Lid1QZZpo"
   },
   "source": [
    "Com o método abaixo carregamos um dos modelos do spacy:\n",
    "\n",
    "```python\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "```\n",
    "\n",
    "Para aplicar o modelo, basta passar o texto para o modelo carregado anteriormente:\n",
    "\n",
    "```python\n",
    "doc = nlp(\"This is some text that I am processing with Spacy\")\n",
    "```\n",
    "\n",
    "Carregue o modelo e imprima doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AjRx4bZxZZpo"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oDsD2THwZZps"
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"This is some text that I am processing with Spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDWkp1tfZZpy"
   },
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VuqCJaIMZZp3"
   },
   "source": [
    "Ao aplicar o modelo carregado a variável <b> doc </b> já possui os embeddings de cada uma das palavras e o embedding da frase, que é a média de todos vetores de todas palavras.\n",
    "\n",
    "```python\n",
    "#vetor da primeira palavra\n",
    "doc[0].vector\n",
    "#vetor agregado pela média - embedding do documento\n",
    "doc.vector\n",
    "```\n",
    "O código abaixo mostra que a média de uma posição em específico dos embeddings de todas as palavras e a posição do embedding do documento possuem o mesmo valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r426C5mvZZp4"
   },
   "outputs": [],
   "source": [
    "def calcula_media_posicao(x):\n",
    "    soma = 0\n",
    "    vector = []\n",
    "    for i in range(0,len(doc)):\n",
    "        vector.append(doc[i].vector)    \n",
    "    \n",
    "    for v in vector:\n",
    "        soma += v[x]\n",
    "    return soma/len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "969rVBBYZZp8"
   },
   "outputs": [],
   "source": [
    "round(calcula_media_posicao(10),6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nmkeEtyQZZqB"
   },
   "outputs": [],
   "source": [
    "round(doc.vector[10], 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gjZQ_jAMZZqF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Aula 3 - IAAM 3_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
