{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A intenção do projeto é criar um chatbot baseado em reviews de filmes para que se possa fazer perguntas e manter uma conversa livre\n",
    "\n",
    "- link do banco de dados https://www.kaggle.com/Cornell-University/movie-dialog-corpus?select=movie_lines.tsv\n",
    "- referências\n",
    ">- https://shanebarker.com/blog/deep-learning-chatbot/\n",
    "> -https://towardsdatascience.com/how-to-create-a-chatbot-with-python-deep-learning-in-less-than-an-hour-56a063bdfc44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/douglas/.local/lib/python3.8/site-packages (3.8.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/douglas/.local/lib/python3.8/site-packages (from gensim) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/douglas/.local/lib/python3.8/site-packages (from gensim) (1.18.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/douglas/.local/lib/python3.8/site-packages (from gensim) (3.0.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /home/douglas/.local/lib/python3.8/site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied: tensorflow in /home/douglas/.local/lib/python3.8/site-packages (2.3.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (0.10.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (1.33.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (1.18.5)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/douglas/.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/douglas/.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.22.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/douglas/.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/douglas/.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (45.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/douglas/.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/douglas/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /home/douglas/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/douglas/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: keras in /home/douglas/.local/lib/python3.8/site-packages (2.4.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/douglas/.local/lib/python3.8/site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: h5py in /home/douglas/.local/lib/python3.8/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/douglas/.local/lib/python3.8/site-packages (from keras) (1.5.2)\n",
      "Requirement already satisfied: six in /home/douglas/.local/lib/python3.8/site-packages (from h5py->keras) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install gensim\n",
    "!pip3 install tensorflow\n",
    "!pip3 install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import gensim\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from scipy.spatial import distance\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = pd.read_csv('./chatdata/movie_lines.tsv', header = None, delimiter=\"\\t\", quoting=3, encoding='ISO-8859-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1045</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>They do not!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1044</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>They do to!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L985</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I hope so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L984</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>She okay?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L925</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Let's go.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>L924</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>Wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>L872</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Okay -- you're gonna need to learn how to lie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>L871</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"L870</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I'm kidding.  You know how sometimes you just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>L869</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Like my fear of wearing pastels?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1   2        3                                                  4\n",
       "0  L1045  u0  m0   BIANCA                                       They do not!\n",
       "1  L1044  u2  m0  CAMERON                                        They do to!\n",
       "2   L985  u0  m0   BIANCA                                         I hope so.\n",
       "3   L984  u2  m0  CAMERON                                          She okay?\n",
       "4   L925  u0  m0   BIANCA                                          Let's go.\n",
       "5   L924  u2  m0  CAMERON                                                Wow\n",
       "6   L872  u0  m0   BIANCA     Okay -- you're gonna need to learn how to lie.\n",
       "7   L871  u2  m0  CAMERON                                                 No\n",
       "8  \"L870  u0  m0   BIANCA  I'm kidding.  You know how sometimes you just ...\n",
       "9   L869  u0  m0   BIANCA                   Like my fear of wearing pastels?"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the index of the conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.columns = ['msg_line', 'user1_id', 'movie_id', 'user_name', 'msg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_char(txt):\n",
    "    return re.sub('[^0-9]','', txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['msg_line_clean'] = [remove_char(msg) for msg in messages['msg_line']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_line</th>\n",
       "      <th>user1_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_line_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1045</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>They do not!</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1044</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>They do to!</td>\n",
       "      <td>1044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L985</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I hope so.</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L984</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>She okay?</td>\n",
       "      <td>984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L925</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Let's go.</td>\n",
       "      <td>925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>L924</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>Wow</td>\n",
       "      <td>924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>L872</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Okay -- you're gonna need to learn how to lie.</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>L871</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>No</td>\n",
       "      <td>871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"L870</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I'm kidding.  You know how sometimes you just ...</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>L869</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Like my fear of wearing pastels?</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  msg_line user1_id movie_id user_name  \\\n",
       "0    L1045       u0       m0    BIANCA   \n",
       "1    L1044       u2       m0   CAMERON   \n",
       "2     L985       u0       m0    BIANCA   \n",
       "3     L984       u2       m0   CAMERON   \n",
       "4     L925       u0       m0    BIANCA   \n",
       "5     L924       u2       m0   CAMERON   \n",
       "6     L872       u0       m0    BIANCA   \n",
       "7     L871       u2       m0   CAMERON   \n",
       "8    \"L870       u0       m0    BIANCA   \n",
       "9     L869       u0       m0    BIANCA   \n",
       "\n",
       "                                                 msg msg_line_clean  \n",
       "0                                       They do not!           1045  \n",
       "1                                        They do to!           1044  \n",
       "2                                         I hope so.            985  \n",
       "3                                          She okay?            984  \n",
       "4                                          Let's go.            925  \n",
       "5                                                Wow            924  \n",
       "6     Okay -- you're gonna need to learn how to lie.            872  \n",
       "7                                                 No            871  \n",
       "8  I'm kidding.  You know how sometimes you just ...            870  \n",
       "9                   Like my fear of wearing pastels?            869  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['msg_line_clean'] = pd.to_numeric(messages['msg_line_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = messages.set_index('msg_line_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_line</th>\n",
       "      <th>user1_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msg_line_clean</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>L1045</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>They do not!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>L1044</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>They do to!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>L985</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I hope so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>L984</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>She okay?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>L925</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Let's go.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>L924</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>Wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>L872</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Okay -- you're gonna need to learn how to lie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>L871</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>\"L870</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I'm kidding.  You know how sometimes you just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>L869</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Like my fear of wearing pastels?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               msg_line user1_id movie_id user_name  \\\n",
       "msg_line_clean                                        \n",
       "1045              L1045       u0       m0    BIANCA   \n",
       "1044              L1044       u2       m0   CAMERON   \n",
       "985                L985       u0       m0    BIANCA   \n",
       "984                L984       u2       m0   CAMERON   \n",
       "925                L925       u0       m0    BIANCA   \n",
       "924                L924       u2       m0   CAMERON   \n",
       "872                L872       u0       m0    BIANCA   \n",
       "871                L871       u2       m0   CAMERON   \n",
       "870               \"L870       u0       m0    BIANCA   \n",
       "869                L869       u0       m0    BIANCA   \n",
       "\n",
       "                                                              msg  \n",
       "msg_line_clean                                                     \n",
       "1045                                                 They do not!  \n",
       "1044                                                  They do to!  \n",
       "985                                                    I hope so.  \n",
       "984                                                     She okay?  \n",
       "925                                                     Let's go.  \n",
       "924                                                           Wow  \n",
       "872                Okay -- you're gonna need to learn how to lie.  \n",
       "871                                                            No  \n",
       "870             I'm kidding.  You know how sometimes you just ...  \n",
       "869                              Like my fear of wearing pastels?  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening conversation sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_seq = pd.read_csv('./chatdata/movie_conversations.tsv', header = None, delimiter=\"\\t\", quoting=3, encoding='ISO-8859-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L194' 'L195' 'L196' 'L197']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L198' 'L199']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L200' 'L201' 'L202' 'L203']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L204' 'L205' 'L206']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L207' 'L208']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L271' 'L272' 'L273' 'L274' 'L275']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L276' 'L277']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L280' 'L281']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L363' 'L364']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L365' 'L366']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2                                     3\n",
       "0  u0  u2  m0         ['L194' 'L195' 'L196' 'L197']\n",
       "1  u0  u2  m0                       ['L198' 'L199']\n",
       "2  u0  u2  m0         ['L200' 'L201' 'L202' 'L203']\n",
       "3  u0  u2  m0                ['L204' 'L205' 'L206']\n",
       "4  u0  u2  m0                       ['L207' 'L208']\n",
       "5  u0  u2  m0  ['L271' 'L272' 'L273' 'L274' 'L275']\n",
       "6  u0  u2  m0                       ['L276' 'L277']\n",
       "7  u0  u2  m0                       ['L280' 'L281']\n",
       "8  u0  u2  m0                       ['L363' 'L364']\n",
       "9  u0  u2  m0                       ['L365' 'L366']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_seq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_seq.columns = ['user1_id', 'user2_id', 'movie_id', 'sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user1_id</th>\n",
       "      <th>user2_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L194' 'L195' 'L196' 'L197']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L198' 'L199']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L200' 'L201' 'L202' 'L203']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L204' 'L205' 'L206']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L207' 'L208']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L271' 'L272' 'L273' 'L274' 'L275']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L276' 'L277']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L280' 'L281']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L363' 'L364']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L365' 'L366']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user1_id user2_id movie_id                              sequence\n",
       "0       u0       u2       m0         ['L194' 'L195' 'L196' 'L197']\n",
       "1       u0       u2       m0                       ['L198' 'L199']\n",
       "2       u0       u2       m0         ['L200' 'L201' 'L202' 'L203']\n",
       "3       u0       u2       m0                ['L204' 'L205' 'L206']\n",
       "4       u0       u2       m0                       ['L207' 'L208']\n",
       "5       u0       u2       m0  ['L271' 'L272' 'L273' 'L274' 'L275']\n",
       "6       u0       u2       m0                       ['L276' 'L277']\n",
       "7       u0       u2       m0                       ['L280' 'L281']\n",
       "8       u0       u2       m0                       ['L363' 'L364']\n",
       "9       u0       u2       m0                       ['L365' 'L366']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_seq.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_conversation(txt):\n",
    "    txt_alt = txt.split(' ')\n",
    "    return txt_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_to_list(seq):\n",
    "    seq_list = [remove_char(s) for s in seq]\n",
    "    return seq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['msg_2'] = '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_conversations(seq_list, df, filter1, filter2):\n",
    "    i = 0\n",
    "    while i in range(len(seq_list)):\n",
    "        if i+1 < len(seq_list):\n",
    "            next_msg = df.loc[int(seq_list[i+1]), filter1]\n",
    "            #print(str(i))\n",
    "            #print(next_msg)\n",
    "            #print(seq_list[i])\n",
    "            df.at[int(seq_list[i]), filter2] = next_msg\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_conversations(['194', '195', '196', '197'], messages, 'msg', 'msg_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Well I thought we'd start with pronunciation if that's okay with you.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.loc[195, 'msg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for conv in conv_seq['sequence']:\n",
    "    #print(conv)\n",
    "    seq = split_conversation(conv)\n",
    "    #print(seq)\n",
    "    #txt_alt = remove_char(txt_alt)      \n",
    "    txt_alt = [remove_char(s) for s in seq]\n",
    "    #print(txt_alt)\n",
    "    link_conversations(txt_alt, messages, 'msg', 'msg_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Well I thought we'd start with pronunciation if that's okay with you.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.loc[194, 'msg_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_line</th>\n",
       "      <th>user1_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msg_line_clean</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>L1045</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>They do not!</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>L1044</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>They do to!</td>\n",
       "      <td>They do not!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>L985</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I hope so.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>L984</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>She okay?</td>\n",
       "      <td>I hope so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>L925</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Let's go.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>L924</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>Wow</td>\n",
       "      <td>Let's go.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>L872</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Okay -- you're gonna need to learn how to lie.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>L871</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>No</td>\n",
       "      <td>Okay -- you're gonna need to learn how to lie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>\"L870</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I'm kidding.  You know how sometimes you just ...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>L869</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Like my fear of wearing pastels?</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>\"L868</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>The \"\"real you\"\".\"</td>\n",
       "      <td>Like my fear of wearing pastels?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>L867</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>What good stuff?</td>\n",
       "      <td>The \"\"real you\"\".\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>L866</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>I figured you'd get to the good stuff eventually.</td>\n",
       "      <td>What good stuff?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>L865</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>Thank God!  If I had to hear one more story ab...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>L864</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Me.  This endless ...blonde babble. I'm like b...</td>\n",
       "      <td>Thank God!  If I had to hear one more story ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>L863</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>What crap?</td>\n",
       "      <td>Me.  This endless ...blonde babble. I'm like b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>L862</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>do you listen to this crap?</td>\n",
       "      <td>What crap?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>L861</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>No...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>\"L860</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Then Guillermo says \"\"If you go any lighter yo...</td>\n",
       "      <td>No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>L699</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>You always been this selfish?</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>L698</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>But</td>\n",
       "      <td>You always been this selfish?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>L697</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>Then that's all you had to say.</td>\n",
       "      <td>But</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>L696</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Well no...</td>\n",
       "      <td>Then that's all you had to say.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>L695</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>You never wanted to go out with 'me did you?</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>L694</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I was?</td>\n",
       "      <td>You never wanted to go out with 'me did you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>\"L693</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>I looked for you back at the party but you alw...</td>\n",
       "      <td>I was?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>L663</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Tons</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>L662</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>Have fun tonight?</td>\n",
       "      <td>Tons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>L578</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>I believe we share an art instructor</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>L577</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>You know Chastity?</td>\n",
       "      <td>I believe we share an art instructor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               msg_line user1_id movie_id user_name  \\\n",
       "msg_line_clean                                        \n",
       "1045              L1045       u0       m0    BIANCA   \n",
       "1044              L1044       u2       m0   CAMERON   \n",
       "985                L985       u0       m0    BIANCA   \n",
       "984                L984       u2       m0   CAMERON   \n",
       "925                L925       u0       m0    BIANCA   \n",
       "924                L924       u2       m0   CAMERON   \n",
       "872                L872       u0       m0    BIANCA   \n",
       "871                L871       u2       m0   CAMERON   \n",
       "870               \"L870       u0       m0    BIANCA   \n",
       "869                L869       u0       m0    BIANCA   \n",
       "868               \"L868       u2       m0   CAMERON   \n",
       "867                L867       u0       m0    BIANCA   \n",
       "866                L866       u2       m0   CAMERON   \n",
       "865                L865       u2       m0   CAMERON   \n",
       "864                L864       u0       m0    BIANCA   \n",
       "863                L863       u2       m0   CAMERON   \n",
       "862                L862       u0       m0    BIANCA   \n",
       "861                L861       u2       m0   CAMERON   \n",
       "860               \"L860       u0       m0    BIANCA   \n",
       "699                L699       u2       m0   CAMERON   \n",
       "698                L698       u0       m0    BIANCA   \n",
       "697                L697       u2       m0   CAMERON   \n",
       "696                L696       u0       m0    BIANCA   \n",
       "695                L695       u2       m0   CAMERON   \n",
       "694                L694       u0       m0    BIANCA   \n",
       "693               \"L693       u2       m0   CAMERON   \n",
       "663                L663       u0       m0    BIANCA   \n",
       "662                L662       u2       m0   CAMERON   \n",
       "578                L578       u2       m0   CAMERON   \n",
       "577                L577       u0       m0    BIANCA   \n",
       "\n",
       "                                                              msg  \\\n",
       "msg_line_clean                                                      \n",
       "1045                                                 They do not!   \n",
       "1044                                                  They do to!   \n",
       "985                                                    I hope so.   \n",
       "984                                                     She okay?   \n",
       "925                                                     Let's go.   \n",
       "924                                                           Wow   \n",
       "872                Okay -- you're gonna need to learn how to lie.   \n",
       "871                                                            No   \n",
       "870             I'm kidding.  You know how sometimes you just ...   \n",
       "869                              Like my fear of wearing pastels?   \n",
       "868                                            The \"\"real you\"\".\"   \n",
       "867                                              What good stuff?   \n",
       "866             I figured you'd get to the good stuff eventually.   \n",
       "865             Thank God!  If I had to hear one more story ab...   \n",
       "864             Me.  This endless ...blonde babble. I'm like b...   \n",
       "863                                                    What crap?   \n",
       "862                                   do you listen to this crap?   \n",
       "861                                                         No...   \n",
       "860             Then Guillermo says \"\"If you go any lighter yo...   \n",
       "699                                 You always been this selfish?   \n",
       "698                                                           But   \n",
       "697                               Then that's all you had to say.   \n",
       "696                                                    Well no...   \n",
       "695                  You never wanted to go out with 'me did you?   \n",
       "694                                                        I was?   \n",
       "693             I looked for you back at the party but you alw...   \n",
       "663                                                          Tons   \n",
       "662                                             Have fun tonight?   \n",
       "578                          I believe we share an art instructor   \n",
       "577                                            You know Chastity?   \n",
       "\n",
       "                                                            msg_2  \n",
       "msg_line_clean                                                     \n",
       "1045                                                            -  \n",
       "1044                                                 They do not!  \n",
       "985                                                             -  \n",
       "984                                                    I hope so.  \n",
       "925                                                             -  \n",
       "924                                                     Let's go.  \n",
       "872                                                             -  \n",
       "871                Okay -- you're gonna need to learn how to lie.  \n",
       "870                                                            No  \n",
       "869                                                             -  \n",
       "868                              Like my fear of wearing pastels?  \n",
       "867                                            The \"\"real you\"\".\"  \n",
       "866                                              What good stuff?  \n",
       "865                                                             -  \n",
       "864             Thank God!  If I had to hear one more story ab...  \n",
       "863             Me.  This endless ...blonde babble. I'm like b...  \n",
       "862                                                    What crap?  \n",
       "861                                                             -  \n",
       "860                                                         No...  \n",
       "699                                                             -  \n",
       "698                                 You always been this selfish?  \n",
       "697                                                           But  \n",
       "696                               Then that's all you had to say.  \n",
       "695                                                             -  \n",
       "694                  You never wanted to go out with 'me did you?  \n",
       "693                                                        I was?  \n",
       "663                                                             -  \n",
       "662                                                          Tons  \n",
       "578                                                             -  \n",
       "577                          I believe we share an art instructor  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing for deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping the just the pair of messages\n",
    "df = messages[messages['msg_2'] != '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_line</th>\n",
       "      <th>user1_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msg_line_clean</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>L1044</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>They do to!</td>\n",
       "      <td>They do not!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>L984</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>She okay?</td>\n",
       "      <td>I hope so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>L924</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>Wow</td>\n",
       "      <td>Let's go.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>L871</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>No</td>\n",
       "      <td>Okay -- you're gonna need to learn how to lie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>\"L870</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I'm kidding.  You know how sometimes you just ...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>\"L868</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>The \"\"real you\"\".\"</td>\n",
       "      <td>Like my fear of wearing pastels?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>L867</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>What good stuff?</td>\n",
       "      <td>The \"\"real you\"\".\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>L866</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>I figured you'd get to the good stuff eventually.</td>\n",
       "      <td>What good stuff?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>L864</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Me.  This endless ...blonde babble. I'm like b...</td>\n",
       "      <td>Thank God!  If I had to hear one more story ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>L863</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>What crap?</td>\n",
       "      <td>Me.  This endless ...blonde babble. I'm like b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               msg_line user1_id movie_id user_name  \\\n",
       "msg_line_clean                                        \n",
       "1044              L1044       u2       m0   CAMERON   \n",
       "984                L984       u2       m0   CAMERON   \n",
       "924                L924       u2       m0   CAMERON   \n",
       "871                L871       u2       m0   CAMERON   \n",
       "870               \"L870       u0       m0    BIANCA   \n",
       "868               \"L868       u2       m0   CAMERON   \n",
       "867                L867       u0       m0    BIANCA   \n",
       "866                L866       u2       m0   CAMERON   \n",
       "864                L864       u0       m0    BIANCA   \n",
       "863                L863       u2       m0   CAMERON   \n",
       "\n",
       "                                                              msg  \\\n",
       "msg_line_clean                                                      \n",
       "1044                                                  They do to!   \n",
       "984                                                     She okay?   \n",
       "924                                                           Wow   \n",
       "871                                                            No   \n",
       "870             I'm kidding.  You know how sometimes you just ...   \n",
       "868                                            The \"\"real you\"\".\"   \n",
       "867                                              What good stuff?   \n",
       "866             I figured you'd get to the good stuff eventually.   \n",
       "864             Me.  This endless ...blonde babble. I'm like b...   \n",
       "863                                                    What crap?   \n",
       "\n",
       "                                                            msg_2  \n",
       "msg_line_clean                                                     \n",
       "1044                                                 They do not!  \n",
       "984                                                    I hope so.  \n",
       "924                                                     Let's go.  \n",
       "871                Okay -- you're gonna need to learn how to lie.  \n",
       "870                                                            No  \n",
       "868                              Like my fear of wearing pastels?  \n",
       "867                                            The \"\"real you\"\".\"  \n",
       "866                                              What good stuff?  \n",
       "864             Thank God!  If I had to hear one more story ab...  \n",
       "863             Me.  This endless ...blonde babble. I'm like b...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processamento_texto(corpus):\n",
    "    #tokenizacao\n",
    "    corpus_alt = re.findall(r\"\\w+(?:'\\w+)?|[^\\w\\s]\", corpus)\n",
    "    #capitalizacao\n",
    "    corpus_alt = [t.lower() for t in corpus_alt]\n",
    "    #lammatization\n",
    "    #sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    \n",
    "    #stemming\n",
    "    #TODO\n",
    "    \n",
    "    #remover stopwords\n",
    "    #stopwords_ = stopwords.words(\"portuguese\")\n",
    "    #corpus_alt = [t for t in corpus_alt if t not in stopwords_]\n",
    "    #remover numero\n",
    "    #corpus_alt = [re.sub(r\"\\d\",\"\",t) for t in corpus_alt]\n",
    "    #remover pontuacoes\n",
    "    #corpus_alt = [t for t in corpus_alt if t not in string.punctuation]\n",
    "\n",
    "    return corpus_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "n = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['msg'][i:n].astype(str), df['msg_2'][i:n].astype(str), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small['msg'] = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small['msg_2'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "# fit the tokenizer on the documents\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode training data set\n",
    "X_train_token = tokenizer.texts_to_matrix(X_train)\n",
    "# encode training data set\n",
    "y_train_token = tokenizer.texts_to_matrix(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows, num_cols = X_train_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/douglas/.local/lib/python3.8/site-packages/scipy/spatial/distance.py:714: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "list_similarity = []\n",
    "for i in range(num_rows):\n",
    "    d = distance.cosine(X_train_token[i], y_train_token[i])\n",
    "    if math.isnan(d):\n",
    "        d = 0.0\n",
    "    list_similarity.append(d)\n",
    "    i+=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small['similarity'] = list_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msg_line_clean</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>When EVIL returns so shall we.</td>\n",
       "      <td>We will be ready Lord.</td>\n",
       "      <td>0.764298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4778</th>\n",
       "      <td>Yeah.</td>\n",
       "      <td>It looks like you bought it off one of the bro...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4787</th>\n",
       "      <td>Then what're you complainin' about? At least n...</td>\n",
       "      <td>I may call you worse than that.</td>\n",
       "      <td>0.858579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5296</th>\n",
       "      <td>When a guy hurts you then comes back bleeding ...</td>\n",
       "      <td>Hey Come on shrink time's over. They wouldn't ...</td>\n",
       "      <td>0.934205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5199</th>\n",
       "      <td>Maybe we should pay Luther a visit.</td>\n",
       "      <td>Let him get some sleep.  He's going to need it.</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5946</th>\n",
       "      <td>Love...</td>\n",
       "      <td>Yes! But \"\"love\"\" isn't the operative word her...</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5515</th>\n",
       "      <td>But what happens if instead of this... Ultimat...</td>\n",
       "      <td>White turns to black.  Light to Dark. Life to ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>And you don't know how they open is that what ...</td>\n",
       "      <td>That's what I'm saying.</td>\n",
       "      <td>0.711325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6054</th>\n",
       "      <td>Yes... you know there's a lot of differences b...</td>\n",
       "      <td>You noticed..</td>\n",
       "      <td>0.786799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5370</th>\n",
       "      <td>I'll buy ya the best dinner in San Francisco.....</td>\n",
       "      <td>Now you're talkin'. See ya...</td>\n",
       "      <td>0.891535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4848</th>\n",
       "      <td>We're on the move. Let's go. As they walk towa...</td>\n",
       "      <td>Do you know how close I was to getting some tr...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6211</th>\n",
       "      <td>6... 5...</td>\n",
       "      <td>Found it?</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6258</th>\n",
       "      <td>Don't tell me you don't know how all this works?</td>\n",
       "      <td>Theoretically yes! The four Stones form the be...</td>\n",
       "      <td>0.925464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4854</th>\n",
       "      <td>Yeah I'm hungry too. I know of a place. Let's ...</td>\n",
       "      <td>Yeah I want mandolins flowers... They move off...</td>\n",
       "      <td>0.807550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5531</th>\n",
       "      <td>The cash man!</td>\n",
       "      <td>Been here long?</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4929</th>\n",
       "      <td>You made that move huh?</td>\n",
       "      <td>While you're at it You can give me the switchb...</td>\n",
       "      <td>0.858579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5304</th>\n",
       "      <td>Do I get to kiss her too?</td>\n",
       "      <td>If she's right and if you don't screw up.</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5230</th>\n",
       "      <td>Let her go.</td>\n",
       "      <td>First the money.</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5201</th>\n",
       "      <td>They must have set up a meeting for the mornin...</td>\n",
       "      <td>So you took the rest of the night off...</td>\n",
       "      <td>0.937006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4497</th>\n",
       "      <td>We got a lot to talk about.</td>\n",
       "      <td>Yeah old times.</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              msg  \\\n",
       "msg_line_clean                                                      \n",
       "5426                               When EVIL returns so shall we.   \n",
       "4778                                                        Yeah.   \n",
       "4787            Then what're you complainin' about? At least n...   \n",
       "5296            When a guy hurts you then comes back bleeding ...   \n",
       "5199                          Maybe we should pay Luther a visit.   \n",
       "5946                                                      Love...   \n",
       "5515            But what happens if instead of this... Ultimat...   \n",
       "6265            And you don't know how they open is that what ...   \n",
       "6054            Yes... you know there's a lot of differences b...   \n",
       "5370            I'll buy ya the best dinner in San Francisco.....   \n",
       "4848            We're on the move. Let's go. As they walk towa...   \n",
       "6211                                                    6... 5...   \n",
       "6258             Don't tell me you don't know how all this works?   \n",
       "4854            Yeah I'm hungry too. I know of a place. Let's ...   \n",
       "5531                                                The cash man!   \n",
       "4929                                      You made that move huh?   \n",
       "5304                                    Do I get to kiss her too?   \n",
       "5230                                                  Let her go.   \n",
       "5201            They must have set up a meeting for the mornin...   \n",
       "4497                                  We got a lot to talk about.   \n",
       "\n",
       "                                                            msg_2  similarity  \n",
       "msg_line_clean                                                                 \n",
       "5426                                       We will be ready Lord.    0.764298  \n",
       "4778            It looks like you bought it off one of the bro...    1.000000  \n",
       "4787                              I may call you worse than that.    0.858579  \n",
       "5296            Hey Come on shrink time's over. They wouldn't ...    0.934205  \n",
       "5199              Let him get some sleep.  He's going to need it.    1.000000  \n",
       "5946            Yes! But \"\"love\"\" isn't the operative word her...    0.666667  \n",
       "5515            White turns to black.  Light to Dark. Life to ...    1.000000  \n",
       "6265                                      That's what I'm saying.    0.711325  \n",
       "6054                                                You noticed..    0.786799  \n",
       "5370                                Now you're talkin'. See ya...    0.891535  \n",
       "4848            Do you know how close I was to getting some tr...    1.000000  \n",
       "6211                                                    Found it?    1.000000  \n",
       "6258            Theoretically yes! The four Stones form the be...    0.925464  \n",
       "4854            Yeah I want mandolins flowers... They move off...    0.807550  \n",
       "5531                                              Been here long?    1.000000  \n",
       "4929            While you're at it You can give me the switchb...    0.858579  \n",
       "5304                    If she's right and if you don't screw up.    1.000000  \n",
       "5230                                             First the money.    1.000000  \n",
       "5201                     So you took the rest of the night off...    0.937006  \n",
       "4497                                              Yeah old times.    1.000000  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 2)                 2328      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 2,337\n",
      "Trainable params: 2,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model - 3 layers. First layer 128 neurons, second layer 64 neurons and 3rd output layer contains number of neurons\n",
    "# equal to number of intents to predict output intent with softmax\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=num_cols, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.0777e-07 - accuracy: 0.1652\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.0777e-07 - accuracy: 0.1833\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.0777e-07 - accuracy: 0.1584\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.0777e-07 - accuracy: 0.1765\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.0777e-07 - accuracy: 0.1516\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.0777e-07 - accuracy: 0.1584\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.0777e-07 - accuracy: 0.1606\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.0777e-07 - accuracy: 0.1697\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.0777e-07 - accuracy: 0.1719\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.0777e-07 - accuracy: 0.1923\n",
      "model created\n"
     ]
    }
   ],
   "source": [
    "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "#fitting and saving the model\n",
    "hist = model.fit(X_train_token, df_small['similarity'], epochs=10, batch_size=20, verbose=1)\n",
    "model.save('chatbot_model.h5', hist)\n",
    "\n",
    "print(\"model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = tokenizer.texts_to_matrix('what is the best movie?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1163) for input Tensor(\"dense_3_input:0\", shape=(None, 1163), dtype=float32), but it was called on an input with incompatible shape (None, 23, 1163).\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(np.array([p]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       ],\n",
       "       [0.5       ],\n",
       "       [0.5032889 ],\n",
       "       [0.5       ],\n",
       "       [0.5       ],\n",
       "       [0.50109696],\n",
       "       [0.5       ],\n",
       "       [0.5       ],\n",
       "       [0.5       ],\n",
       "       [0.5       ],\n",
       "       [0.5       ],\n",
       "       [0.5       ],\n",
       "       [0.5       ],\n",
       "       [0.5       ],\n",
       "       [0.5       ],\n",
       "       [0.5       ],\n",
       "       [0.5       ],\n",
       "       [0.5       ],\n",
       "       [0.5       ],\n",
       "       [0.5       ],\n",
       "       [0.50109696],\n",
       "       [0.5       ],\n",
       "       [0.5       ]], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR_THRESHOLD = 0.25\n",
    "results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by strength of probability\n",
    "results.sort(key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_list = []\n",
    "i = 0\n",
    "for i in range(len(results)):\n",
    "    #return_list.append({\"intent\": df_small['msg_2'][i], \"probability\": str(i)})\n",
    "    print(results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Template model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model - 3 layers. First layer 128 neurons, second layer 64 neurons and 3rd output layer contains number of neurons\n",
    "# equal to number of intents to predict output intent with softmax\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=4, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "#fitting and saving the model\n",
    "hist = model.fit(([1,2,3,4],[1,2,3,4],[1,2,3,4]), [1,2,3], epochs=2, batch_size=3, verbose=1)\n",
    "model.save('chatbot_model.h5', hist)\n",
    "\n",
    "print(\"model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
