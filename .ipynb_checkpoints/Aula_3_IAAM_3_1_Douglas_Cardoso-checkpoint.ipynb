{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-Mgum7LZZmf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting afinn\n",
      "  Downloading afinn-0.1.tar.gz (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 144 kB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: afinn\n",
      "  Building wheel for afinn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for afinn: filename=afinn-0.1-py3-none-any.whl size=53450 sha256=232d59b7dbbe0e5de922ae677d6ac10da33e5c5239956b4207903beb21f4baf4\n",
      "  Stored in directory: /home/douglas/.cache/pip/wheels/f6/6f/c3/b305c5107a17618f2938a067d5ffcbb556909d82398762089e\n",
      "Successfully built afinn\n",
      "Installing collected packages: afinn\n",
      "Successfully installed afinn-0.1\n",
      "/bin/bash: python: command not found\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting textblob\n",
      "  Downloading textblob-0.15.3-py2.py3-none-any.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 738 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nltk>=3.1\n",
      "  Downloading nltk-3.5.zip (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 310 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: click in /usr/lib/python3/dist-packages (from nltk>=3.1->textblob) (7.0)\n",
      "Collecting joblib\n",
      "  Downloading joblib-0.17.0-py3-none-any.whl (301 kB)\n",
      "\u001b[K     |████████████████████████████████| 301 kB 417 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex\n",
      "  Downloading regex-2020.10.15-cp38-cp38-manylinux2010_x86_64.whl (675 kB)\n",
      "\u001b[K     |████████████████████████████████| 675 kB 662 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.50.2-py2.py3-none-any.whl (70 kB)\n",
      "\u001b[K     |████████████████████████████████| 70 kB 561 kB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434674 sha256=e47490e6df84146a9e331932459bf2c1f5f016006a46dbf4a72d25bf5c8c8bbf\n",
      "  Stored in directory: /home/douglas/.cache/pip/wheels/ff/d5/7b/f1fb4e1e1603b2f01c2424dd60fbcc50c12ef918bafc44b155\n",
      "Successfully built nltk\n",
      "Installing collected packages: joblib, regex, tqdm, nltk, textblob\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[K     |████████████████████████████████| 125 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/lib/python3/dist-packages (from vaderSentiment) (2.22.0)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pyemd\n",
      "  Downloading pyemd-0.5.1.tar.gz (91 kB)\n",
      "\u001b[K     |████████████████████████████████| 91 kB 482 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.9.0 in /home/douglas/.local/lib/python3.8/site-packages (from pyemd) (1.19.2)\n",
      "Building wheels for collected packages: pyemd\n",
      "  Building wheel for pyemd (setup.py) ... \u001b[?25l|"
     ]
    }
   ],
   "source": [
    "!pip install afinn\n",
    "!python -m textblob.download_corpora\n",
    "!pip install -U textblob\n",
    "!pip install vaderSentiment\n",
    "!pip install pyemd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SR9dcTSYZZml"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from unidecode import unidecode\n",
    "import pandas as pd\n",
    "import bz2\n",
    "import gensim\n",
    "import warnings\n",
    "import numpy as np\n",
    "from gensim.models import word2vec\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AjOYV0cfZZmq"
   },
   "source": [
    "# Carregando os embeddings\n",
    "\n",
    "Aqui vamos utilizar os embeddings para realizar as seguintes atividades:\n",
    "\n",
    "- análise de simlaridade\n",
    "- classificação de documentos\n",
    "\n",
    "<b> Carregue os embeddings treinados, como vimos na Aula 2. É o mesmo arquivo que iremos utilizar</b>\n",
    "\n",
    "Link: https://drive.google.com/open?id=1zI8pGfbUHuU_0wY_FV4tD6w6ZCUJTQbh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XqMDMgrBZZmr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqZJuktuZZmv"
   },
   "source": [
    "# Similaridade de Documentos\n",
    "\n",
    "Para realizar a similaridade entre documentos, utilize as frases abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T-YjfkcTZZmw"
   },
   "outputs": [],
   "source": [
    "frase1 = \"Excelente produto chegou antes do prazo indico e recomendo produto bom pois já testei e foi mais que aprovado\" \n",
    "frase2 = \"SUPER RECOMENDO, PREÇO, QUALIDADE #BRASTEMP, EFICIÊNCIA NA ENTREGA, E FACILIDADE DE PAGAMENTO. MUITO BOM!!!\"\n",
    "frase3 = \"A tampa do fogão veio com problemas com o pino de encaixe solto e precisa de reparos\"\n",
    "frase4 = \"Fogão ótimo!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNGfjS5RZZm1"
   },
   "source": [
    "## Distância de Jaccard\n",
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "1) Faça um método que calcule a similaridade de Jaccard e aplique para os seguintes pares de frases:\n",
    "\n",
    "- Frase1 e Frase2\n",
    "- Frase1 e Frase3\n",
    "- Frase2 e Frase3\n",
    "- Frase1 e Frase4\n",
    "\n",
    "Observação: lembrando que você precisa aplicar um pre-processamento nessas frases antes de aplicar o método.\n",
    "Faça:\n",
    "\n",
    "- Lower\n",
    "- Remoção StopWords\n",
    "- Remoção Pontuação\n",
    "- Tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yn2YYL7bZZm2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ke1PVggcZZm8"
   },
   "source": [
    "<b> Atividade </b>\n",
    "\n",
    "2) Qual par de frase teve maior simlaridade? E qual teve menor? Este resultado faz sentido? Explique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3g7wRRl_ZZm9"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ND3usAELZZm-"
   },
   "source": [
    "## Distância de Cosseno\n",
    "\n",
    "Aqui iremos calcular a distância do cosseno utilizando duas formas, que aprendemos na aula passada, para representar o texto.\n",
    "\n",
    "- Bag of Words (BOW) \n",
    "- Embedding\n",
    "\n",
    "Observação:\n",
    "\n",
    "Existem duas formas de trabalhar com o cosseno:\n",
    "\n",
    "<b> Distância </b>: quanto menor mais perto estão as frases.\n",
    "<b> Similaridade </b>: quanto maior mais perto estão as frases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_Qw93ZLZZm-"
   },
   "source": [
    "### BOW - Distância do cosseno\n",
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "3) Calcule a distância do cosseno utilizando a representação CountVectorizer e aplique para os seguintes pares de frases:\n",
    "\n",
    "- Frase1 e Frase2\n",
    "- Frase1 e Frase3\n",
    "- Frase2 e Frase3\n",
    "- Frase1 e Frase4\n",
    "\n",
    "Observação: no CountVectorizer utilizem as frases já pre-processadas da atividade anterior. Mas para aplicá-las no fit_transform, cada frase deve ser um string (sem estar tokenizada) dentro de uma lista.\n",
    "\n",
    "```python\n",
    "#exemplo\n",
    "distance.cosine(frase1, frase2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7CzqpPPGZZm_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rcFS1MKzZZnE"
   },
   "source": [
    "<b> Atividade </b>\n",
    "\n",
    "\n",
    "4) Qual par de frase teve maior distância? E qual teve menor? Este resultado faz sentido? Explique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buNHHZPgZZnF"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3G4ckzlZZnN"
   },
   "source": [
    "### Embedding - Distância do cosseno\n",
    "\n",
    "Para calcular o embedding de cada uma das frases, utilize o modelo carregado inicialmente. \n",
    "\n",
    "Cada palavra tem um vetor, para formar o embedding da frase tire a média de todos os vetores.\n",
    "\n",
    "Utilize as frases já pre-processadas\n",
    "\n",
    "<b> Atividade </b> \n",
    "\n",
    "5) Calcule a distância do cosseno utilizando a representação Embedding e aplique para os seguintes pares de frases:\n",
    "\n",
    "- Frase1 e Frase2\n",
    "- Frase1 e Frase3\n",
    "- Frase2 e Frase3\n",
    "- Frase1 e Frase4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rRO8RnLgZZnO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgZWHiGSZZnT"
   },
   "source": [
    "<b>Atividade </b>\n",
    "\n",
    "6) Qual par de frase teve maior distância? E qual teve menor? Este resultado faz sentido? Explique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsFFxOoeZZnU"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hx5acLVhZZne"
   },
   "source": [
    "## WMD\n",
    "\n",
    "O WMD já está incorporado ao Word2Vec\n",
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "7) Calcule a distância WMD e aplique para os seguintes pares de frases:\n",
    "\n",
    "- Frase1 e Frase2\n",
    "- Frase1 e Frase3\n",
    "- Frase2 e Frase3\n",
    "- Frase1 e Frase4\n",
    "\n",
    "Observação: use a variável já tokenizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o0881q7vZZne"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsIENn25ZZni"
   },
   "source": [
    "<b> Atividade </b>\n",
    "\n",
    "8) Qual par de frase teve maior distância? E qual teve menor? Este resultado faz sentido? Explique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhC4OvGWZZnj"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXHGivtDZZnk"
   },
   "source": [
    "# Classificação de Documentos\n",
    "\n",
    "A clssificação de documentos é muito útil em vários aspectos. Um dos tipos de classificação de texto é a análise de sentimentos.\n",
    "\n",
    "A fim de ilustrar a classificação de documentos iremos criar um modelo para classificar uma frase como positiva ou negativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhCOoEn7ZZno"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "9) Carregue o dataset com o pandas e depois dê o head no dataframe.\n",
    "\n",
    "\n",
    "Link download: https://drive.google.com/open?id=15azJWdEEPGsXQGiDmEOseTBJcquWvBQc\n",
    "\n",
    "<b> Este dataset é sobre revisões de filmes do IMDB. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eI0oXiOoZZnp"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"imdb-reviews-pt-br.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJYAOZecZZnv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCKr5KPMZZnz"
   },
   "source": [
    "## Representação dos dados\n",
    "\n",
    "O sentimento positivo e negativo iremos binarizar cada um deles. Seja 1 positivo e 0 negativo.\n",
    "\n",
    "Iremos representar o texto de duas formas:\n",
    "\n",
    "- Bag of Words (BOW)\n",
    "- Embedding\n",
    "\n",
    "Depois iremos comparar o resultado de cada um deles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "POkSAiYMZZn0"
   },
   "source": [
    "### Representação Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0mYbWgcZZn1"
   },
   "source": [
    "<b> Atividade </b>\n",
    "\n",
    "10) Faça a representação dos sentimentos. 1 positivo; 0 negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aBkDjo4VZZn2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8VgGgUnZZn8"
   },
   "source": [
    "### Bag of Words (BOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xirBWWCzZZn-"
   },
   "source": [
    "<b> Atividade </b>\n",
    "\n",
    "11) Aplique o pré-processamento listado abaixo na coluna ``text_pt`` (crie uma nova coluna ```text_pt_sem_stopwords``` no dataframe para armazenar este dado processado):\n",
    "\n",
    "- Remova as stopwords do texto\n",
    "- Remova as pontuções\n",
    "- Mantenha o texto sem tokenização, ou seja uma string\n",
    "\n",
    "<b> Dica: </b> use o ```progress_apply``` para exibir a barra de progresso:\n",
    "\n",
    "```python\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "df[\"colunas\"].progress_apply(lambda x: preprocessamento(x))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DnJokm8VZZn-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TddT2Y6JZZoC"
   },
   "source": [
    "<b> Atividade </b>\n",
    "\n",
    "12) Aplique a representação do texto processado anteriormente com CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axSZo69tZZoC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mELsQ0tvZZoF"
   },
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSUe-Yr_ZZoG"
   },
   "source": [
    "<b> Atividade </b>\n",
    "\n",
    "13) Aplique o pré-processamento listado abaixo na coluna ``text_pt`` (crie uma nova coluna ```text_pt_sem_stopwords_token``` no dataframe para armazenar este dado processado):\n",
    "\n",
    "- Aplique lower\n",
    "- Remova as stopwords do texto\n",
    "- Remova as pontuções\n",
    "- Mantenha o texto com tokenização\n",
    "\n",
    "<b> Dica: </b> use o ```progress_apply``` para exibir a barra de progresso:\n",
    "\n",
    "```python\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "df[\"colunas\"].progress_apply(lambda x: preprocessamento(x))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rBJxB_SsZZoH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZPhMIrWZZoM"
   },
   "source": [
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "14) Aplique a representação do texto com Embeddings. Cada palavra tem um embedding, o embedding da frase é a média de todos embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4gg0S5NZZoM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqPJf0yLZZoQ"
   },
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_xhW7e2ZZoQ"
   },
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kpcc167FZZoR"
   },
   "source": [
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "15) Faça a divisão dados dados em treino e teste como no exemplo abaixo:\n",
    "\n",
    "```python\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(X_bag, target,random_state=123)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E3MeGchRZZoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0ggm8ZLZZoY"
   },
   "source": [
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "16) Treine com uma regressão logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJN8KMHiZZoa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivlITfC2ZZof"
   },
   "source": [
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "17) Calcule as métricas de resultado utilizando método abaixo:\n",
    "\n",
    "```python\n",
    "print(classification_report(y_test_bow, y_pred))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TsfRxqjSZZog"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eiulNTGNZZoj"
   },
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6abN65iqZZok"
   },
   "source": [
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "18) Faça a divisão dados dados em treino e teste como no exemplo abaixo:\n",
    "\n",
    "Verifique o shape do X treino e X teste. Caso eles estejam com apenas uma dimensão, você precisa tranformá-los para duas dimensões, caso contrário ocorrerá erro no treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yn57b04_ZZol"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9BR0H7fZZop"
   },
   "source": [
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "19) Treine com uma regressão logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hJI29fY2ZZoq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvIYI1lJZZow"
   },
   "source": [
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "20) Calcule as métricas de resultado utilizando método abaixo:\n",
    "\n",
    "```python\n",
    "print(classification_report(y_test_bow, y_pred))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClFB32whZZox"
   },
   "source": [
    "#### Calcule as métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G-dRYhR_ZZoy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sp62Sb1ZZo1"
   },
   "source": [
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "21) Compare os resultados obtidos com o BagOfWords e com o Embedding. Explique os possíveis motivos desta diferença."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RShZ0680ZZo2"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-oH0GQfZZo3"
   },
   "source": [
    "# Análise de sentimentos\n",
    "\n",
    "O modelo que criamos anteriormente é para ilustrar como podemos realizar classificação de documentos.\n",
    "Quando a tarefa é sobre análise de sentimentos, temos duas opções: treinar nosso próprio modelo, como feito anteriormente ou utilizar uma das inúmeras ferramentas prontas.\n",
    "\n",
    "Vamos testar as seguintes ferramentas:\n",
    "\n",
    "- Vader\n",
    "- Textblob\n",
    "- Affin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilpNXE0cZZo3"
   },
   "source": [
    "Nesta atividade iremos utilizar as duas variáveis abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pq0dLI9JZZo4"
   },
   "outputs": [],
   "source": [
    "texto_neg = df.loc[0, \"text_en\"]\n",
    "texto_pos = df.loc[49431, \"text_en\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dB-FuBgZZo9"
   },
   "source": [
    "## Vader\n",
    "\n",
    "<b> Apenas Inglês </b>\n",
    "\n",
    "O VADER (Valence Aware Dictionary e sEntiment Reasoner) é uma ferramenta de análise de sentimentos baseada em regras e léxico, especificamente identifica os sentimentos expressos nas mídias sociais.\n",
    "\n",
    "- positive sentiment: compound score >= 0.05\n",
    "- neutral sentiment: (compound score > -0.05) e (compound score < 0.05)\n",
    "- negative sentiment: compound score <= -0.05\n",
    "\n",
    "Mais informações: https://github.com/cjhutto/vaderSentiment\n",
    "\n",
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "22) Aplique este método nas revisões ```texto_pos``` e ```texto_neg```.\n",
    "Para aplicar:\n",
    "\n",
    "```python\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "analyzer.polarity_scores(texto)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vZE5KL-9ZZo9"
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qzsgloUpZZpB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDrJTCfKZZpE"
   },
   "source": [
    "## TextBlob\n",
    "\n",
    "<b> Apenas inglês </b>\n",
    "\n",
    "https://www.presentslide.in/2019/08/sentiment-analysis-textblob-library.html\n",
    "\n",
    "<b> Atividade </b>\n",
    " \n",
    "23) Aplique este método nas revisões ```texto_pos``` e ```texto_neg```.\n",
    "Para aplicar:\n",
    "\n",
    "```python\n",
    "sentence=TextBlob(texto)\n",
    "sentence.sentiment\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9IvBg5sZZpE"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-BV6UkOZZpJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xwk7dHuFZZpO"
   },
   "source": [
    "## Afinn\n",
    "\n",
    "- Valor maior que 0 indica sentimento positivo\n",
    "- Valor menor que 0 indica sentimento negativo\n",
    "\n",
    "<b> Atividade </b>\n",
    "\n",
    "24) Aplique este método nas revisões ```texto_pos``` e ```texto_neg```.\n",
    "Para aplicar:\n",
    "\n",
    "```python\n",
    "afinn = Afinn()\n",
    "afinn.score(texto)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2FS5AUsZZpP"
   },
   "outputs": [],
   "source": [
    "from afinn import Afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iF8E0CjzZZpX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkhkDVIxZZpa"
   },
   "source": [
    "<b> Atividade </b>\n",
    "\n",
    "25) Para você, qual ferramenta teve melhor comportamento?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWImUeS0ZZpb"
   },
   "source": [
    "# Dica:\n",
    "## Quando for trabalhar com um dataset em inglês, a biblioteca Spacy facilita!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gONqxhviZZpc"
   },
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3hj3KE97ZZph"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zW0GLnhVZZpn"
   },
   "source": [
    "O scpay forne um pacote que já tem série de modelos já treinados em NLP. Inclusive para os embeddings em inglês.\n",
    "\n",
    "Para mais informações vá em:\n",
    "\n",
    "https://spacy.io/models/en#en_core_web_md\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v02Lid1QZZpo"
   },
   "source": [
    "Com o método abaixo carregamos um dos modelos do spacy:\n",
    "\n",
    "```python\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "```\n",
    "\n",
    "Para aplicar o modelo, basta passar o texto para o modelo carregado anteriormente:\n",
    "\n",
    "```python\n",
    "doc = nlp(\"This is some text that I am processing with Spacy\")\n",
    "```\n",
    "\n",
    "Carregue o modelo e imprima doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AjRx4bZxZZpo"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oDsD2THwZZps"
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"This is some text that I am processing with Spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDWkp1tfZZpy"
   },
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VuqCJaIMZZp3"
   },
   "source": [
    "Ao aplicar o modelo carregado a variável <b> doc </b> já possui os embeddings de cada uma das palavras e o embedding da frase, que é a média de todos vetores de todas palavras.\n",
    "\n",
    "```python\n",
    "#vetor da primeira palavra\n",
    "doc[0].vector\n",
    "#vetor agregado pela média - embedding do documento\n",
    "doc.vector\n",
    "```\n",
    "O código abaixo mostra que a média de uma posição em específico dos embeddings de todas as palavras e a posição do embedding do documento possuem o mesmo valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r426C5mvZZp4"
   },
   "outputs": [],
   "source": [
    "def calcula_media_posicao(x):\n",
    "    soma = 0\n",
    "    vector = []\n",
    "    for i in range(0,len(doc)):\n",
    "        vector.append(doc[i].vector)    \n",
    "    \n",
    "    for v in vector:\n",
    "        soma += v[x]\n",
    "    return soma/len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "969rVBBYZZp8"
   },
   "outputs": [],
   "source": [
    "round(calcula_media_posicao(10),6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nmkeEtyQZZqB"
   },
   "outputs": [],
   "source": [
    "round(doc.vector[10], 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gjZQ_jAMZZqF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Aula 3 - IAAM 3_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
